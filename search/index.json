[{"content":"TL;DR Google Colaboratory（Colab）のPythonのバージョンは長らく3.6でしたが、2021年2月24日に3.7にアップグレードされました1。 これによって、Python 3.6系にしか対応していない2電波天文学のデータ解析ソフトウェアCASAがColab上で動かなくなってしまいました。 この記事では、3.7系対応のプレリリース版CASA6.2をColabにインストールし、公式のノートブックが動くことを確認してみました3。\nHow to install まず、リリース版のインストール方法はCASA docsに記載されている以下の方法です。\napt-get install libgfortran3 pip install --index-url https://casa-pip.nrao.edu/repository/pypi-casa-release/simple casatools pip install --index-url https://casa-pip.nrao.edu/repository/pypi-casa-release/simple casatasks これをColabで実行すると、Python 3.7対応のcasatoolsが存在しないのでエラーが出てインストールできません。\nLooking in indexes: https://casa-pip.nrao.edu/repository/pypi-casa-release/simple ERROR: Could not find a version that satisfies the requirement casatools (from versions: none) ERROR: No matching distribution found for casatools そこで、https://casa-pip.nrao.eduを検索してPython 3.7対応のプレリリース版を探します。 記事作成時点では、6.2.0.100などが良さそうです4。 というわけで、プレリリース版のインストール方法ではこれらを手動でダウンロードします。\napt-get install libgfortran3 wget https://casa-pip.nrao.edu/repository/casa-test-wheel/packages/casatools/6.2.0.100/casatools-6.2.0.100-cp37-cp37m-manylinux2010_x86_64.whl wget https://casa-pip.nrao.edu/repository/casa-test-wheel/packages/casatasks/6.2.0.100/casatasks-6.2.0.100-py3-none-any.whl wget https://casa-pip.nrao.edu/repository/casa-aux-wheel/packages/casadata/2021.4.5/casadata-2021.4.5-py3-none-any.whl pip install casatools-6.2.0.100-cp37-cp37m-manylinux2010_x86_64.whl pip install casatasks-6.2.0.100-py3-none-any.whl pip install casadata-2021.4.5-py3-none-any.whl Operation check 以上のインストール方法を書いた公式のノートブックのコピーを作成しました。 実行したところ、少なくともノートブックの内容（listobs, tclean, exportfits）は動作することが確認できました。\nReferences  CASA: Common Astronomy Software Applications Obtaining and Installing — CASA Documentation CASA6_demo.ipynb (CASA official) CASA6.2_demo.ipynb (Made by the author)    https://github.com/googlecolab/colabtools/issues/1422#issuecomment-784545501 \u0026#x21a9;\u0026#xfe0e;\n 2021年4月時点の最新版CASA6.1の話です \u0026#x21a9;\u0026#xfe0e;\n ノートブックの内容が動くだけで、全ての動作を保証するものではありません \u0026#x21a9;\u0026#xfe0e;\n マイナー以下のバージョンの違いは筆者は良く分かりませんでした… \u0026#x21a9;\u0026#xfe0e;\n   ","date":"2021-04-10T12:18:00+09:00","image":"https://astropengu.in/posts/34/cover_hua91a964e34f64e973df46c877c21b75d_138631_120x120_fill_q75_box_smart1.jpg","permalink":"https://astropengu.in/posts/34/","title":"Python 3.7になったGoogle ColabでCASAを動かしてみる"},{"content":"TL;DR ☃️ 以前の記事（ADC/MDAS への Linuxbrew のインストール）で、天文データセンター（ADC）の多波長データ解析システム（MDAS）に Linuxbrew をインストールする際の手順をまとめました。 ところが、システムにインストールされているcURLとGitのバージョンが古いため、2021年2月時点で最新版のLinuxbrewでは新規インストールやアップデートの際にエラーが出てしまいます。 この記事では、最新版のcURLとGitを管理者権限なしでインストールすることで、これを回避する方法をまとめました。\n最新版のcURLのインストール MDASにログイン後、以下のスクリプトを実行することで、USER_LOCAL直下に最新版のcURLがインストールされます。\nUSER_LOCAL=$HOME/.local CURL_VERSION=7.74.0 wget https://curl.se/download/curl-$CURL_VERSION.tar.gz tar xf curl-$CURL_VERSION.tar.gz cd curl-$CURL_VERSION ./configure --prefix=$USER_LOCAL make install 最新版のGitのインストール 続いて、以下のスクリプトを実行することで、USER_LOCAL直下に最新版のGitがインストールされます。\nUSER_LOCAL=$HOME/.local GIT_VERSION=2.30.0 wget https://github.com/git/git/archive/v$GIT_VERSION.tar.gz tar xf v$GIT_VERSION.tar.gz cd git-$GIT_VERSION make configure ./configure --prefix=$USER_LOCAL make install 環境変数の設定 最後に、諸々の環境変数を設定・反映させます。 特にHOMEBREW_*が重要で、手動でインストールしたcURL・GitをシステムのものだとLinuxbrewに認識させるのに必要です。\nUSER_LOCAL=\u0026#39;$HOME/.local\u0026#39; BASH_PROFILE=$HOME/.bash_profile echo \u0026#39;export PATH=$PATH:\u0026#39;$USER_LOCAL/bin \u0026gt;\u0026gt; $BASH_PROFILE echo \u0026#39;export HOMEBREW_DEVELOPER=1\u0026#39; \u0026gt;\u0026gt; $BASH_PROFILE echo \u0026#39;export HOMEBREW_CURL_PATH=\u0026#39;$USER_LOCAL/bin/curl \u0026gt;\u0026gt; $BASH_PROFILE echo \u0026#39;export HOMEBREW_GIT_PATH=\u0026#39;$USER_LOCAL/bin/git \u0026gt;\u0026gt; $BASH_PROFILE source $BASH_PROFILE Linuxbrewのインストール（初回のみ） すでにLinuxbrewがインストール済みの場合、以下の手順は必要ありません。\n/bin/bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026#34; References  Git - Gitのインストール build and install curl from source brew/brew.sh at master · Homebrew/brew  ","date":"2021-02-03T15:28:00+09:00","image":"https://astropengu.in/posts/33/image_hu672e83f2b78d71f64037e92b0c4e88f0_433651_120x120_fill_q75_box_smart1.jpg","permalink":"https://astropengu.in/posts/33/","title":"ADC/MDASへのLinuxbrewのインストール（2021年版）"},{"content":"TL;DR 🎍 Pythonのクラス・メタクラス関連は毎回こんがらかるのでメモ。__new__・__init__・typeの役割を正しく理解するのが重要。 まず、以下では通常のクラス定義として以下を考えることにする。\n# 通常のクラス定義 class Class: def __init__(self, arg): self.arg = arg __new__はインスタンスを生成・__init__はインスタンスを初期化 __new__は初期化されていないクラスのインスタンスを生成するのに使われる。__init__はインスタンスが生成された後に初期化のため呼び出される。 __init__によってインスタンスが生成されている訳ではないことに注意する（Pythonで__init__をコンストラクタと呼ばないのはそのためである）。 つまり、以下の2つは等価である。\n# 通常のインスタンス生成 obj = Class(arg) # __new__と__init__を明示的に呼び出したインスタンス生成 obj = Class.__new__(Class, arg) obj.__init__(arg) __new__は一般的には定義されていないので、その場合は基底クラスobjectの__new__が呼び出されることになる。 つまり、以下とも等価である。\n# __new__が定義されていない場合のインスタンス生成 obj = object.__new__(Class, arg) obj.__init__(arg) __new__の使い所としてはインスタンス生成のカスタマイズが考えられるだろう。 例えば、以下はシングルトン（複数のインスタンスで同一性が保証されたクラス）の実装例である。\n# __new__を使ったシングルトンの実装 class Singleton: def __new__(cls): if not hasattr(cls, \u0026#34;_instance\u0026#34;): cls._instance = super().__new__(cls) return cls._instance print(Singleton() is Singleton()) # True 他の用途としては、タプルやNumPyなどイミュータブルなオブジェクトのサブクラスが考えられる。\nメタクラスはtypeのカスタマイズ メタクラスの役割はクラス生成そのもののカスタマイズである。 そもそも、クラスは以下のように組み込みクラスのtypeを使ってtype(name, bases, dict)で動的に生成できる。 つまり、通常のクラス定義は以下と等価である。\n# typeによるクラス定義 def __init__(self, arg): self.arg = arg Class = type(\u0026#34;Class\u0026#34;, (object,), {\u0026#34;__init__\u0026#34;: __init__}) これは、typeがメタクラス、つまりインスタンスがクラスとなるようなクラスであることを表している。 metaclassを使ったクラス定義は、カスタマイズされたtypeを使ってクラス生成することに相当する。 つまり、metaclass=metaの場合のクラス生成は以下のように行われることを意味する。\n# metaclass=metaの場合のクラス定義 Class = meta(\u0026#34;Class\u0026#34;, (object,), {\u0026#34;__init__\u0026#34;: __init__}) また、以下が通常のクラス定義と等価であることが分かるはずである。\n# metaclass=typeの場合のクラス定義 class Class(metaclass=type): def __init__(self, arg): self.arg = arg メタクラスの使い所は、__new__や__init__では行えないようなクラスに対するメソッド等の動的な追加・変更が考えられるだろう。 例えば、以下はキャメルケースのメソッド名をスネークケースに変更する実装例である。\n# メソッド名のスネークケース化 # install from PyPI from inflection import underscore def snake_case(name, bases, dict): new_dict = {underscore(k): v for k, v in dict.items()} return type(name, bases, new_dict) class Example(metaclass=snake_case): def CamelCaseMethod(self): pass obj = Example() obj.camel_case_method() # ok obj.CamelCaseMethod() # AttributeError ちなみに、最終的にtypeが呼ばれさえすれば良いので、metaclassに渡すのはcallableなオブジェクトであればクラスでなくてもかまわない。 実際、上の例では関数をmetaclassに渡している（ただし、typeのインスタンスを返すだけなのでメタクラスではないことに注意）。\nメタクラスとクラスデコレータ クラスを動的に変更するもう一つの方法としてクラスデコレータがある。 これは、クラスを受け取りクラスを返す関数として実装し、関数デコレータと同様にクラス定義の上にデコレートするものである。 例えば、先ほどのスネークケースの実装例は、クラスデコレータでは以下のように書ける。\n# メソッド名のスネークケース化（クラスデコレータ版） def snake_case(cls): for name, obj in vars(cls).items(): new_name = underscore(name) if name != new_name: setattr(cls, new_name, obj) delattr(cls, name) return cls @snake_case class Example: def CamelCaseMethod(self): pass 生成されたクラスをカスタマイズする用途であれば、クラスデコレータは直感的で分かりやすい。 例えば、Python 3.7で導入されたデータクラスではクラスデコレータが使われている。 私見だが、引数を持つデコレータを作成することができるのもクラスデコレータの利点かもしれない。\n一方、クラスデコレータでカスタマイズできるのは主にクラス変数とインスタンスメソッドであり、クラス自身が持つメソッド（つまりクラスをtypeのインスタンスと見たときのインスタンスメソッド）を変更することはできない。 例えば、クラスをprintしたときの表示はメタクラスを使わないとカスタマイズできない。\n# クラスのreprのカスタマイズ class Meta(type): def __repr__(self): return self.__name__ + \u0026#34;!\u0026#34; class Custom(metaclass=Meta): pass print(Custom) # Custom! また、動的なクラス継承などもメタクラスの範疇である。\n# クラス名に応じた継承先の変更 def meta(name, bases, dict): return type(name, (eval(name.lower()), *bases), dict) class List(metaclass=meta): pass class Tuple(metaclass=meta): pass print(List([0, 1, 2])) # [0, 1, 2] print(Tuple([0, 1, 2])) # (0, 1, 2) このようにメタクラスの方が強力だが、反面どうしても抽象的な概念が登場して分かりづらくなるので、なるべくクラスデコレータまでに留めておきたいところ。 また、関数デコレータと同様に、クラスをもとにした新しいクラスを返すのであればクラスデコレータでも可能なので、表面上はこれで良い場合も多いだろう。\n# クラスのreprのカスタマイズ（クラスデコレータ版） class Meta(type): def __repr__(self): return self.__name__ + \u0026#34;!\u0026#34; def deco(cls): return Meta(cls.__name__, cls.__bases__, dict(cls.__dict__)) @deco class Custom: pass print(Custom) # Custom! まとめ  __new__はインスタンス生成のカスタマイズ __init__はインスタンスのカスタマイズ メタクラスはtypeのカスタマイズ クラスデコレータはtypeインスタンス（＝クラス）のカスタマイズ  References  組み込み関数 — Python 3.9.1 ドキュメント dataclasses \u0026mdash; データクラス — Python 3.9.1 ドキュメント Python の new ってなに？ | 民主主義に乾杯 Python のメタクラスとクラスデコレータってなに？ | 民主主義に乾杯 inflection · PyPI  ","date":"2020-12-29T17:48:00+09:00","image":"https://astropengu.in/posts/32/image_hud757c1cb85c28ff6302647a0a6aa5a74_1830888_120x120_fill_q75_box_smart1.jpg","permalink":"https://astropengu.in/posts/32/","title":"Pythonのクラスとメタクラスまとめ"},{"content":"TL;DR 🌻 xarrayは多次元配列にメタデータ（軸のラベルなど）がくっついたデータを扱うためのツールとして、NumPyやpandasと同様にデータ解析で使われるPythonパッケージですが、様々なデータをxarray（のDataArray）で扱っていく中で以下のように感じることが増えてきました。\n 多次元配列の軸（dimensions）や型（dtype）を指定した配列生成関数がほしい 同様にメタデータ（coordinates）にも軸・型・デフォルトの値を指定したい 上2つを満たしたNumPyのones()のような特別な配列生成をしたい データ独自の処理（メソッド）を定義したい  これらをかなえる方法は色々考えられますが、Python 3.7から標準ライブラリに登場したデータクラス（dataclasses）が同じような悩み？をシンプルな書き方で解決していることに気づきました。そこで、データクラスと同様の書き方でユーザ定義のDataArrayクラスを作成するためのパッケージ「xarray-custom」を公開しましたのでご紹介します（pipでインストールできます）。\nfrom xarray_custom import ctype, dataarrayclass @dataarrayclass(accessor=\u0026#39;img\u0026#39;) class Image: \u0026#34;\u0026#34;\u0026#34;DataArray class to represent images.\u0026#34;\u0026#34;\u0026#34; dims = \u0026#39;x\u0026#39;, \u0026#39;y\u0026#39; dtype = float x: ctype(\u0026#39;x\u0026#39;, int) = 0 y: ctype(\u0026#39;y\u0026#39;, int) = 0 def normalize(self): return self / self.max() 以下ではこのコードの仕組みを、PythonのデータクラスやDataAraryに触れながら解説していきます。\nPython\u0026rsquo;s dataclass まず、Pythonのデータクラスとはユーザ定義のデータ構造を簡単に作成するための機能（クラスデコレータ）です。\nfrom dataclasses import dataclass @dataclass class Coordinates: x: float y: float @classmethod def origin(cls): return cls(0.0, 0.0) def norm(self): return (self.x ** 2 + self.y **2) ** 0.5 このようにクラスを定義すると、\ncoord = Coordinates(x=3, y=4) のようにデータを格納するクラスを作成してくれます（本来は__init__()など諸々の特殊メソッドの実装が必要）。このようにデータクラスを定義することの利点としては以下が考えられるかと思います。\n 格納する値に名前・型（型ヒントのみ）・デフォルト値を持たせることができる 特別なデータ生成（上の例ではorigin()）をクラスメソッドで実現できる データ独自の処理（上の例ではnorm()）をインスタンスメソッドで実現できる  xarray\u0026rsquo;s DataArray 次に、xarray（DataArray）のデータ構造を見ていきます。DataArrayはNumPyの多次元配列（data）、軸（dimensions; メタデータの一種）、メタデータ（coordinates）からなるデータ構造を取ります。以下の例は、xyの2軸からなる単色画像をデータをDataArrayで表現しているつもりです。\nfrom xarray import DataArray image = DataArray(data=[[0, 1], [2, 3]], dims=(\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;), coords={\u0026#39;x\u0026#39;: [0, 1], \u0026#39;y\u0026#39;: [0, 1]}) print(image) # \u0026lt;xarray.DataArray (x: 2, y: 2)\u0026gt; # array([[0., 1.], # [2., 3.]]) # Coordinates: # * x (x) int64 0 1 # * y (y) int64 0 1 DataArrayはクラスなので、ユーザ定義のDataArrayを定義するための一般的な方法はDataArrayをサブクラスとした新しいクラスを作成することです。しかし、__init__()などに定義をハードコードしてしまうと使い回しが効かないという問題があります。また、xarrayやpandasではそもそもサブクラス化を積極的に推奨しておらず、アクセサ（accessor）という特別なオブジェクトを介してユーザ定義の処理などを実装するのが良いとしています。\n One standard solution to this problem is to subclass Dataset and/or DataArray to add domain specific functionality. However, inheritance is not very robust. It’s easy to inadvertently use internal APIs when subclassing, which means that your code may break when xarray upgrades. Furthermore, many builtin methods will only return native xarray objects. (Extending xarray - xarray 0.15.0 documentation)\n xarray\u0026rsquo;s dataarrayclass ようやく本題です。冒頭に書いたような要望を実現するには、xarray（DataArray）の事情も考慮すると、\n （メタ）データの定義をハードコードせずに配列生成する方法を提供する アクセサを介したユーザ定義の処理を提供する これらをシンプルな書き方でできるようにする  ことが必要だということが分かりました。そこで、xarray-customではPythonのデータクラスに慣い、ユーザ定義のDataArrayクラスをクラスデコレータ（dataarrayclass）で動的に改変することで実現することにしました。xarray-customを使うと上の単色画像の例は以下のように定義できます。\nfrom xarray_custom import ctype, dataarrayclass @dataarrayclass(accessor=\u0026#39;img\u0026#39;) class Image: \u0026#34;\u0026#34;\u0026#34;DataArray class to represent images.\u0026#34;\u0026#34;\u0026#34; dims = \u0026#39;x\u0026#39;, \u0026#39;y\u0026#39; dtype = float x: ctype(\u0026#39;x\u0026#39;, int) = 0 y: ctype(\u0026#39;y\u0026#39;, int) = 0 def normalize(self): return self / self.max() データクラスを知っていることで、このコードで何をしているのかは説明なしでも何となく理解していただけたのではないでしょうか。ここでのポイントは以下の3点です。\n クラス変数でデータの軸（'x', 'y'）・型（float）を指定する 特別な型付きのクラス変数で軸を含むメタデータの名前・軸・型・デフォルト値を指定する ユーザ定義の処理（メソッド）はアクセサ（img）配下に自動的に移動させる  ここで、ctypeはメタデータを定義する特別な型（クラス）を生成するための関数です。それでは実際にユーザ定義の配列を生成してみましょう。\nimage = Image([[0, 1], [2, 3]], x=[0, 1], y=[0, 1]) print(image) # \u0026lt;xarray.DataArray (x: 2, y: 2)\u0026gt; # array([[0., 1.], # [2., 3.]]) # Coordinates: # * x (x) int64 0 1 # * y (y) int64 0 1 軸とメタデータが予め定義されているので、上のDataArrayの例と比べてとても簡潔に書けることが分かります。データクラスと異なるのは、型の情報が配列の型を決めるのに実際に使われるという点です。上の例では、integerのリストがDataArray内ではfloatに型変換されています。（暗黙の）型変換ができない場合はValueErrorが送出されます。また、型を指定しないこともできます（その場合、任意の型のオブジェクトを受け付けます）。\nInstance methods via an accessor xarrayの方針に従い、クラスに定義したインスタンスメソッド（上の例ではnormalize()）はアクセサを介して実行することができます。アクセサなしで実行するとAttributeErrorが送出されます。\nnormalized = image.img.normalize() print(normalized) # \u0026lt;xarray.DataArray (x: 2, y: 2)\u0026gt; # array([[0. , 0.33333333], # [0.66666667, 1. ]]) # Coordinates: # * x (x) int64 0 1 # * y (y) int64 0 1 Special functions as class methods 特別な配列生成として、NumPyに慣いzeros()・ones()・empty()・full()がクラスメソッドとして自動的に追加されています。zeros_like()などはxarrayのトップレベル関数に定義されていますのでそちらを使いましょう。\nuniform = Image.ones((2, 3)) print(uniform) # \u0026lt;xarray.DataArray (x: 2, y: 3)\u0026gt; # array([[1., 1., 1.], # [1., 1., 1.]]) # Coordinates: # * x (x) int64 0 0 # * y (y) int64 0 0 0 Misc ここまでの話で、dataarrayclassでもDataArrayのサブクラス化を結局行っているのでは？と思った方もいらっしゃるかもしれません。が、実際は生成されるDataArrayは本物のDataArrayインスタンスです。逆に言うと、上の例ではImageインスタンスではありません。\nprint(type(image)) # xarray.core.dataarray.DataArray これは、dataarrayclass内部では__init__()ではなく__new__()を動的に生成しており、__new__()がDataArrayを返すようにしているためです。このため、普通のクラスから作られたインスタンスのように、クラス変数等にアクセスできないことに注意が必要です。\nxarrayはNumPyやpandasに比べると記事数も少なく知名度も低いのかなという印象ですが、多次元配列を扱う課題には間違いなく有用ですのでどんどん使っていきたいところです。xarray-customは開発初期で機能も少ないですが、こうした拡張機能の開発や記事を通して少しでもコミュニティに貢献できればと思っております。\nReferences  xarray-custom  Documentation   xarray  Terminology Extending xarray   pandas  Registering custom accessors    ","date":"2020-07-24T01:46:17+09:00","image":"https://astropengu.in/posts/31/image_huab13b69368037f19875f50bf380cdf80_225815_120x120_fill_q75_box_smart1.jpg","permalink":"https://astropengu.in/posts/31/","title":"Pythonのデータクラスのようにxarrayのデータ構造を定義する"},{"content":"TL;DR 🎏 Python の小ネタですが、dictionary で存在しない key にアクセスした際に送出される KeyError のメッセージに、存在する keys 一覧を表示させる方法をメモしておきます。\nKeysInfoDict 以下のような dictionary のサブクラスを作成することで実現します。\nclass KeysInfoDict(dict): \u0026#34;\u0026#34;\u0026#34;Dict that shows all keys when KeyError rises.\u0026#34;\u0026#34;\u0026#34; def __missing__(self, key): keys = \u0026#39;, \u0026#39;.join(map(repr, self)) raise KeyError(f\u0026#39;Choose one from: {keys}\u0026#39;) Key が存在しなかった場合に呼ばれるメソッド __missing__() に処理を設定するのがポイントです。\n self[key] の実装において辞書内にキーが存在しなかった場合に、 dict のサブクラスのために dict.__getitem__() によって呼び出されます。 3. データモデル — Python 3.7.3 ドキュメント\n また、key の repr をメッセージに含めることで、例えば key が 1 なのか '1' なのかを正しく表示するようにしています。\nExample \u0026gt;\u0026gt;\u0026gt; d = KeysInfoDict(a=1, b=2, c=3) \u0026gt;\u0026gt;\u0026gt; d[\u0026#39;d\u0026#39;] Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 5, in __missing__ KeyError: \u0026#34;Choose one from: \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;\u0026#34; 用途としては、例えばパッケージ内部の dictionary で、エラーは送出した上でユーザに使用可能な keys 一覧をサジェストしたい、といった場合かなと思います。\n","date":"2019-05-20T00:21:21+09:00","image":"https://astropengu.in/posts/30/image_hu66482708b471a939ec4727ecbb2ebafe_277748_120x120_fill_q75_box_smart1.jpg","permalink":"https://astropengu.in/posts/30/","title":"Python dictionary の KeyError に keys 一覧を表示させる"},{"content":"TL;DR 🎏 xarrayはラベル付き多次元配列のセットを扱うためのPythonパッケージで、PyDataによって開発されています。 Pythonにはもともと、多次元配列を効率的に扱うことのできるNumPy、ラベル付き1次元配列（系列データ）のセットを扱うpandasがあり、xarrayはpandasの多次元版と考えることができます。 xarrayは最初のリリースが2014年と比較的新しいですが、pandas側でもxarrayの利用を促しているようです。 実際、pandasには2次元配列のセットと扱うためのPanelと呼ばれるデータ構造がありましたが、xarrayの登場によってdeprecatedとなり、代わりにto_xarray()メソッドがpd.DataFrameに追加されています。\n Panel was deprecated in the 0.20.x release, showing as a DeprecationWarning. Using Panel will now show a FutureWarning. The recommended way to represent 3-D data are with a MultiIndex on a DataFrame via the to_frame() or with the xarray package. Pandas provides a to_xarray() method to automate this conversion.\nv0.20.1 (May 5, 2017) — pandas 0.24.2 documentation\n こうした背景の一方、xarrayはpandasほど使われていないのかなあという印象です。 例えば、Google Trendsによると、pandasとxarrayの検索数には大きな開きがあることが分かります。 xarrayを紹介している記事等も（日本語、英語ともに）pandasのそれと比べて圧倒的に少ないです。\n実際問題、多次元配列というのは一般的には使われていない（使う必要がない）のかもしれません（例えば、Excelで表現できるデータであればpandasの範疇）。 しかし、研究分野の測定データは多次元に普通になり得ますし、データには測定時刻や座標等のラベルが付くことがほとんどですので、ラベル付き多次元配列というのは結構需要があるはずです。\nそこで、この記事を含む一連の記事では、xarrayについて（自分の理解を深める意味でも）紹介します。 タイトルの通り、xarrayのデータ構造やメソッドはpandasのそれと共通する部分が多いので、これらを比較してまとめるのが良さそうです。 今回の記事ではxarrayのデータ構造のみの紹介です。\nScope 一連の記事を書く際に使用したxarray、pandas、およびNumPyのバージョンは以下の通りです。\n xarray: v0.12.1 pandas: v0.24.2 numpy: v1.16.3  これらは以下のようにインポートすることにします。\n\u0026gt;\u0026gt;\u0026gt; import pandas as pd \u0026gt;\u0026gt;\u0026gt; import xarray as xr \u0026gt;\u0026gt;\u0026gt; import numpy as np Data structures Dataset \u0026amp; DataArray 以下の図はDatasetと呼ばれる、pandasでのDataFrame（pd.DataFrame）に相当するデータ構造を示したものです。 これは例えば、ある地域における気温と降水量のメッシュデータを、時系列で保存したものと見ることができます。 ここで、(x,y)はメッシュ座標、(lat, lon)は経緯度座標として、別々に表現されているような状況です。\n  dataset-diagram.png \nData Structures — xarray 0.12.1 documentation\n xarrayでは、pandasの系列データ（pd.Series）に相当するデータが多次元配列になり得ます。 この図では、全ての要素がそれに当たり、DataArray（xr.DataArray）と呼ばれます。\nCoordinates \u0026amp; dimensions pandasでは特定の系列データをラベル（pd.Index）に割り当てますが、xarrayでも同様に、特定の（複数も可）DataArrayをラベル化することができます。 この図では、気温と降水量が測定データなので、この2つ以外の全ての要素を割り当てるのが良さそうです。 ラベル化されたDataArray(s)は**coordinate(s)**と特別に呼ばれます。 一方、xarrayではラベル化によってオブジェクトが変化する（i.e., pd.Series→pd.Index）ことはなく、あくまでDataArrayのままです。\n最後に、pandasにはない概念として、DatasetやDataArrayの各次元軸を規定する**dimension(s)**があります。 Dimensionsは軸名と軸の値を持つラベルとして、1次元のDataArrayで表現されます。 これらは、coordinatesとは別に生成することもできますし、1次元のcoordinatesを割り当てることもできます。 この図では、例えば(x, y, t)をdimensionsに割り当てるのが良いかもしれません。\nこれらの概念をpandasとの比較でまとめると以下の通りです。\n    xarray pandas     次元軸 Dimension(s) (xr.DataArray) n/a   ラベル Coordinate(s) (xr.DataArray) (Multi)Index (pd.(Multi)Index)   データ DataArray (xr.DataArray) Series (pd.Series)   データセット Dataset (xr.Dataset) DataFrame (pd.DataFrame)    Examples 以上を踏まえ、実際にDatasetを生成してみましょう。 以下のスクリプトは、xarray documentationに記載されている例を元に、上の説明に合うように書き直したものになります。 Dimensionsはdimsとして軸名のタプルで、coordinatesはcoordsとして\u0026lt;name\u0026gt;: (\u0026lt;dims\u0026gt;, \u0026lt;value\u0026gt;)の辞書で表現されます。\n# fix random seed np.random.seed(2019) # observed data temperature = 15 + 8*np.random.randn(2, 2, 3) precipitation = 10 * np.random.rand(2, 2, 3) # coordinates latitude = [[42.25, 42.21], [42.63, 42.59]] longitude = [[-99.83, -99.32], [-99.79, -99.23]] x = [\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;] y = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;] t = pd.date_range(\u0026#39;2014-09-06\u0026#39;, periods=3) reference_time = pd.Timestamp(\u0026#39;2014-09-05\u0026#39;) # create dataarrays dims = (\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;t\u0026#39;) coords = {\u0026#39;latitude\u0026#39;: ((\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;), latitude), \u0026#39;longitude\u0026#39;: ((\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;), longitude), \u0026#39;reference_time\u0026#39;: reference_time, \u0026#39;x\u0026#39;: (\u0026#39;x\u0026#39;, x), \u0026#39;y\u0026#39;: (\u0026#39;y\u0026#39;, y), \u0026#39;t\u0026#39;: (\u0026#39;t\u0026#39;, t)} temperature = xr.DataArray(temperature, coords, dims) precipitation = xr.DataArray(precipitation, coords, dims) # create dataset ds = xr.Dataset() ds[\u0026#39;temperature\u0026#39;] = temperature ds[\u0026#39;precipitation\u0026#39;] = precipitation DataArray まずはDataArrayを表示させてみます。 以下のように、NumPy arrayにcoordinatesがくっついた文字列が出力されます。 (x, y, t)に注目すると、名前の横に*が表示されていることが分かりますが、これらのcoordinatesがdimensionsとして割り当てられていることを表しています。\n\u0026gt;\u0026gt;\u0026gt; temperature \u0026lt;xarray.DataArray (x: 2, y: 2, t: 3)\u0026gt; array([[[13.258568, 21.571643, 26.850222], [25.654912, 12.105077, 20.484871]], [[19.590091, 17.301821, 13.114926], [22.627922, 1.482998, 12.240458]]]) Coordinates: latitude (x, y) float64 42.25 42.21 42.63 42.59 longitude (x, y) float64 -99.83 -99.32 -99.79 -99.23 reference_time datetime64[ns] 2014-09-05 * x (x) \u0026lt;U1 \u0026#39;1\u0026#39; \u0026#39;2\u0026#39; * y (y) \u0026lt;U1 \u0026#39;a\u0026#39; \u0026#39;b\u0026#39; * t (t) datetime64[ns] 2014-09-06 2014-09-07 2014-09-08 次に、coordinateにアクセスしてみます。 これも上で説明した通り、coordinatesもDataArrayであることが分かります。 (lat, lon)はdimensionsが(x, y)なので、元のDataArrayのcoordinatesのうち、(x, y)に含まれるcoordinates（lat自身も含む）が引き継がれています。\n\u0026gt;\u0026gt;\u0026gt; temperature.coords[\u0026#39;latitude\u0026#39;] \u0026lt;xarray.DataArray \u0026#39;latitude\u0026#39; (x: 2, y: 2)\u0026gt; array([[42.25, 42.21], [42.63, 42.59]]) Coordinates: latitude (x, y) float64 42.25 42.21 42.63 42.59 longitude (x, y) float64 -99.83 -99.32 -99.79 -99.23 reference_time datetime64[ns] 2014-09-05 * x (x) \u0026lt;U1 \u0026#39;1\u0026#39; \u0026#39;2\u0026#39; * y (y) \u0026lt;U1 \u0026#39;a\u0026#39; \u0026#39;b\u0026#39; 最後に、個々のDataArrayの持つNumPy arrayにはvaluesアトリビュートでアクセスできます。\n\u0026gt;\u0026gt;\u0026gt; temperature.values array([[[13.25856829, 21.57164284, 26.85022247], [25.65491234, 12.10507702, 20.48487065]], [[19.59009141, 17.30182133, 13.11492592], [22.62792195, 1.48299758, 12.24045835]]]) Dataset Datasetを表示させてみます。 DataArrayの一覧がdata variablesとして表示されています。 データが多様な次元を持つため、pandas DataFrameのような表形式のすっきりとした表示にはなりませんが、データ構造を理解していれば情報がまとまっていることが分かるかと思います。\n\u0026gt;\u0026gt;\u0026gt; ds \u0026lt;xarray.Dataset\u0026gt; Dimensions: (t: 3, x: 2, y: 2) Coordinates: latitude (x, y) float64 42.25 42.21 42.63 42.59 longitude (x, y) float64 -99.83 -99.32 -99.79 -99.23 reference_time datetime64[ns] 2014-09-05 * x (x) \u0026lt;U1 \u0026#39;1\u0026#39; \u0026#39;2\u0026#39; * y (y) \u0026lt;U1 \u0026#39;a\u0026#39; \u0026#39;b\u0026#39; * t (t) datetime64[ns] 2014-09-06 2014-09-07 2014-09-08 Data variables: temperature (x, y, t) float64 13.26 21.57 26.85 ... 22.63 1.483 12.24 precipitation (x, y, t) float64 1.629 8.892 1.485 ... 5.783 2.993 8.372 最後に、個々のDataArrayには辞書形式でアクセスできます。\n\u0026gt;\u0026gt;\u0026gt; ds[\u0026#39;temperature\u0026#39;] 今回はここまでです。 次回はDataset、DataArrayのメソッドをpandasと比較してまとめたいと思います。\nReferences  xarray: N-D labeled arrays and datasets in Python — xarray 0.12.1 documentation pandas: powerful Python data analysis toolkit — pandas 0.24.2 documentation Numpy and Scipy Documentation — Numpy and Scipy documentation  ","date":"2019-05-01T16:05:17+09:00","image":"https://astropengu.in/posts/29/image_huab13b69368037f19875f50bf380cdf80_225815_120x120_fill_q75_box_smart1.jpg","permalink":"https://astropengu.in/posts/29/","title":"Pandasとセットで理解するxarray：データ構造編"},{"content":"TL;DR 🌸 ウェブサイトの Hugo theme として、しばらくの間 Minimo を使ってきましたが、 新年度を迎えて心機一転？ということでさらにミニマムな Hello Friend に変更しました。 サイドバーなしの one column で、メニューバーの右上からライト・ダークテーマの切り替えをユーザ側でできます。 かなりシンプルな作りのテーマのため、これまで Minimo ではできていたサイト内検索など、いくつかの機能が現在使えませんが、近いうちに実装しようと思います。\nReferences  Hugo Minimo Hello Friend  ","date":"2019-04-15T11:00:49+09:00","permalink":"https://astropengu.in/posts/28/","title":"Hugo theme を変更しました"},{"content":"TL;DR ☃️ SSHの公開鍵配布を簡単にやる を読んでなるほどなと思ったので、自分の環境でもやってみることにしました。 つまり、GitHub に登録した SSH 公開鍵が URL で公開されていることを利用して、これを各種サーバに設置する公開鍵として使おうということです。 暗号強度にさえ気を使っていれば、面倒な公開鍵のサーバへの設置をコマンド一発で行うことができ、ついでに GitHub clone/push なども SSH 経由で行うことができる (HTTPS の場合の personal token が不要) のため便利そうです。\nOperation policy  秘密鍵 (と公開鍵) の生成はクライアントごとに 1 個だけ作成する  この際、暗号強度は十分高める (RSA 4096 bit など)   公開鍵は GitHub で公開し、これをサーバの ~/.ssh/authorized_keys に登録する  登録は、(サーバのネット接続前提だが) 以下のコマンドで行える    $ curl -sS https://github.com/astropenguin.keys \u0026gt;\u0026gt; ~/.ssh/authorized_keys Make an SSH key pair on client ここでは仮に test_rsa 1という秘密鍵を作成し、公開鍵 test_rsa.pub を公開するとします。 まず、クライアント上で新規鍵を作成します。 この際、デフォルトでは RSA 2048 bit の鍵長となるので、以下のように明示的に変更します。\n$ cd ~/.ssh $ ssh-keygen -t rsa -b 4096 -C user@host -f test_rsa -t で鍵の種類を、 -b で鍵長を、 -C で公開鍵の最後に書かれるコメント2を、 -f で秘密鍵の名前を指定します。 出来上がった鍵が所望の種類、鍵長になっていることを以下のコマンドで確認しておきます。\n$ ssh-keygen -lf test_rsa 4096 SHA256:wXz5ff3T9ETG+exBF5IpzvRwhJcpOidKexcvkA61Kn0 user@host (RSA) 上記の設定通りの内容になっているので大丈夫ですね。\nPaste public key on GitHub 上記で作成した 公開鍵を GitHub に登録します。 まず、公開鍵の中身のテキストを何らかの方法でコピーします。 ちなみに macOS ならば、以下のコマンドでクリップボードに入ります。\n$ cat test_rsa.pub | pbcopy 次に、ブラウザで https://github.com/settings/keys を開き、 New SSH Key から公開鍵を登録します。 Title の部分には鍵のコメント (user@host) を書いておくと良いでしょう3。\n \n最後に、クライアントから SSH 経由で GitHub に接続できることを確認します。 以下のように successfully authenticated と言われれば OK です。\n$ ssh -T -i test_rsa git@github.com Hi astropenguin! You\u0026#39;ve successfully authenticated, but GitHub does not provide shell access. References  SSHの公開鍵配布を簡単にやる | 綺麗に死ぬITエンジニア    実際はデフォルト名 (id_rsa) でクライアント間で共通にしておくと色々便利だと思います。 \u0026#x21a9;\u0026#xfe0e;\n コメントは GitHub に登録した際に消されてしまうようですが、念のため書いておく方が良いでしょう。 \u0026#x21a9;\u0026#xfe0e;\n 何も書かないと、公開鍵に書かれたコメントが自動的に入るようです。 \u0026#x21a9;\u0026#xfe0e;\n   ","date":"2019-02-11T16:14:36+09:00","permalink":"https://astropengu.in/posts/27/","title":"GitHub で SSH 公開鍵を公開する"},{"content":"TL;DR ☃️ Matplotlib でプロット以外の余白部分を透明にした図を保存する際のメモです。 何も考えずに plt.savefig() で transparent=True としてしまうと、以下のようにプロット部分も透明になってしまいます。\n   transparent=False transparent=True            この挙動は、plt.savefig() の docstrings にも書かれています。\n If True, the axes patches will all be transparent; the figure patch will also be transparent unless facecolor and/or edgecolor are specified via kwargs. This is useful, for example, for displaying a plot on top of a colored background on a web page. The transparency of these patches will be restored to their original values upon exit of this function.\n Make only margins transparent そこで、transparent を指定するのではなく、図全体の背景となるオブジェクト (fig.patch) を明示的に透明にしてしまうことにします。 これは、以下のようなコードで実現できるはずです。\nimport matplotlib.pyplot as plt plt.style.use(\u0026#39;fivethirtyeight\u0026#39;) # make fig, axes and plot something fig, ax = plt.subplots(...) ax.plot(...) # make figure\u0026#39;s background tranparent fig.patch.set_alpha(0) # save figure fig.savefig(...) これの結果は以下の通りです。 余白部分だけが透明になっており、プロットの部分は指定したスタイル通りの色が付いていることが確認できました。\n   transparent=False patch.set_alpha(0)            References  早く知っておきたかったmatplotlibの基礎知識、あるいは見た目の調整が捗るArtistの話 - Qiita  ","date":"2019-02-11T16:00:09+09:00","permalink":"https://astropengu.in/posts/26/","title":"Matplotlib で図の余白のみを透明にする"},{"content":"TL;DR 🎍 タイムゾーンを扱う Python パッケージを開発した際に調べた情報をまとめておきます。 そもそも Python におけるタイムゾーンは、tzinfo と呼ばれるオブジェクトによって表現されます。 これは、標準ライブラリの datetime.tzinfo クラスのサブクラスとして、標準ライブラリの datetime.timezone や外部ライブラリ pytz によって提供されています。\n以下では、これらを使ってどのように tzinfo を取得・使用できるのかを紹介します。 その際、Python スクリプトでは以下のようなインポートを仮定しています。\n\u0026gt;\u0026gt;\u0026gt; import pytz \u0026gt;\u0026gt;\u0026gt; import geocoder \u0026gt;\u0026gt;\u0026gt; from timezonefinder import TimezoneFinder \u0026gt;\u0026gt;\u0026gt; from datetime import datetime, timedelta, timezone, tzinfo このうち、pytz・geocoder・timezonefinder は外部ライブラリです。 ただし、pytz は Python documentation でも紹介されているように、ほとんど標準ライブラリ的な扱いをされていると思われます。\nHow to get tzinfo tzinfo を様々な方法で取得する方法をまとめます。 ここでは datetime.tzinfo クラスと区別するため、取得したオブジェクトの変数名は tz として書いています。\nタイムゾーン ID から指定する まずはベーシックな方法から。 例えば、日本のタイムゾーン ID は Asia/Tokyo なので、以下のように tzinfo を取得します。\n\u0026gt;\u0026gt;\u0026gt; query = \u0026#39;Asia/Tokyo\u0026#39; \u0026gt;\u0026gt;\u0026gt; tz = pytz.timezone(query) \u0026gt;\u0026gt;\u0026gt; tz \u0026lt;DstTzInfo \u0026#39;Asia/Tokyo\u0026#39; LMT+9:19:00 STD\u0026gt; ちなみに、全てのタイムゾーン ID は以下のように確認することができます。\n\u0026gt;\u0026gt;\u0026gt; pytz.all_timezones [\u0026#39;Africa/Abidjan\u0026#39;, \u0026#39;Africa/Accra\u0026#39;, \u0026#39;Africa/Addis_Ababa\u0026#39;, ..., \u0026#39;Zulu\u0026#39;] UTC からのオフセット値で指定する UTC (協定世界時) からの任意のオフセット値を持つ tzinfo を取得したいときは、以下のようにします。\n\u0026gt;\u0026gt;\u0026gt; query = 9.0 \u0026gt;\u0026gt;\u0026gt; tz = timezone(timedelta(hours=query)) \u0026gt;\u0026gt;\u0026gt; tz datetime.timezone(datetime.timedelta(0, 32400)) 以下のように文字列に変換することで読みやすい感じになります。\n\u0026gt;\u0026gt;\u0026gt; str(tz) \u0026#39;UTC+09:00\u0026#39; 経度緯度から求める 実際の開発では、ある場所の経度緯度からタイムゾーンを求めたい場合も多いと思います。 その際は、外部ライブラリ timezonefinder を使うことで簡単に取得できます。\n\u0026gt;\u0026gt;\u0026gt; query = {\u0026#39;lng\u0026#39;: 135, \u0026#39;lat\u0026#39;: 35} \u0026gt;\u0026gt;\u0026gt; tf = TimezoneFinder() \u0026gt;\u0026gt;\u0026gt; tz = pytz.timezone(tf.timezone_at(**query)) \u0026gt;\u0026gt;\u0026gt; tz \u0026lt;DstTzInfo \u0026#39;Asia/Tokyo\u0026#39; LMT+9:19:00 STD\u0026gt; ちなみに、検索すると pytzwhere を使用している例を見かけますが、timezonefinder の方が省メモリかつ高速だそうです。 最近の開発もこちらの方が活発っぽいので、これを使っておくのが良さそうです。\n Comparison to pytzwhere - MrMinimal64/timezonefinder  場所名から求める さらに、ある場所名から直接タイムゾーンを求めたい場合、場所名→経度緯度への変換を何かしらの方法で行う必要があります。 ここでは、OpenStreetMap からジオコーディングが可能な geocoder を使った例を紹介します。\n\u0026gt;\u0026gt;\u0026gt; query = \u0026#39;名古屋市\u0026#39; \u0026gt;\u0026gt;\u0026gt; g = geocoder.osm(query) \u0026gt;\u0026gt;\u0026gt; lnglat = {\u0026#39;lng\u0026#39;: g.lng, \u0026#39;lat\u0026#39;: g.lat} \u0026gt;\u0026gt;\u0026gt; tf = TimezoneFinder() \u0026gt;\u0026gt;\u0026gt; tz = pytz.timezone(tf.timezone_at(**lnglat)) \u0026gt;\u0026gt;\u0026gt; tz \u0026lt;DstTzInfo \u0026#39;Asia/Tokyo\u0026#39; LMT+9:19:00 STD\u0026gt; 他にも、Google Maps API で API キーを取得して、Time Zone API を叩くといった方法もあります。\n\u0026gt;\u0026gt;\u0026gt; import googlemaps \u0026gt;\u0026gt;\u0026gt; client = googlemaps.Client(key) \u0026gt;\u0026gt;\u0026gt; result = client.timezone((lat, lng)) \u0026gt;\u0026gt;\u0026gt; tz = result[\u0026#39;timeZoneId\u0026#39;] UTC を指定する 最後に、UTC は各ライブラリで特別な方法で指定します。\n\u0026gt;\u0026gt;\u0026gt; tz = pytz.utc # also: pytz.UTC or timezone.utc \u0026gt;\u0026gt;\u0026gt; tz \u0026lt;UTC\u0026gt; How to use tzinfo 取得した tzinfo (tz) の実際の使い方をまとめます。 まず、上でどの手法で取得した tz も datetime.tzinfo のサブクラスであることを確認しておきましょう。\n\u0026gt;\u0026gt;\u0026gt; isinstance(tz, tzinfo) True 日付に応じたタイムゾーンを求める 夏時間を採用する地域では、日付によってタイムゾーン名と UTC からのオフセット値が変わります。 tzinfo では以下のメソッドで datetime.datetime オブジェクトを与えることで、日付に応じた値の取得が可能です。 まずはタイムゾーン名から。\n\u0026gt;\u0026gt;\u0026gt; tz = pytz.timezone(\u0026#39;Europe/Amsterdam\u0026#39;) \u0026gt;\u0026gt;\u0026gt; tz.tzname(datetime(2019, 1, 1)) \u0026#39;CET\u0026#39; \u0026gt;\u0026gt;\u0026gt; tz.tzname(datetime(2019, 8, 1)) \u0026#39;CEST\u0026#39; 次に UTC オフセット値。 こちらは、datetime.timedelta オブジェクトによって表現されます。\n\u0026gt;\u0026gt;\u0026gt; tz.utcoffset(datetime(2019, 1, 1)) datetime.timedelta(0, 3600) # UTC+01:00 \u0026gt;\u0026gt;\u0026gt; tz.utcoffset(datetime(2019, 8, 1)) datetime.timedelta(0, 7200) # UTC+02:00 タイムゾーンを持つ日付を扱う Python の日付は、datetime.datetime に tzinfo を指定しない場合はタイムゾーンを持たない (timezone-naive な) オブジェクト、指定した場合はタイムゾーンを持つ (timezone-aware な) オブジェクトになります。 例えば、以下のように datetime オブジェクトを作成した場合は timezone-naive となります。\n\u0026gt;\u0026gt;\u0026gt; dt_naive = datetime(2019, 1, 1) datetime.datetime(2019, 1, 1, 0, 0) # timezone-naive timezone-aware なオブジェクトは、以下のように localize メソッドに timezone-naive なオブジェクトを与えてあげることで作成します。 オブジェクトを表示すると、tzinfo が含まれていることが分かります。\n\u0026gt;\u0026gt;\u0026gt; dt_aware = tz.localize(dt_naive) \u0026gt;\u0026gt;\u0026gt; dt_aware datetime.datetime(2019, 1, 1, 0, 0, tzinfo=\u0026lt;DstTzInfo \u0026#39;Europe/Amsterdam\u0026#39; CET+1:00:00STD\u0026gt;) ちなみに、timezone-aware → timezone-naive の変換は、以下の通りです。\n\u0026gt;\u0026gt;\u0026gt; dt_aware.replace(tzinfo=None) datetime.datetime(2019, 1, 1, 0, 0) タイムゾーンの変換 timezone-aware なオブジェクトは、astimezone メソッドで他のタイムゾーンを持つオブジェクトに変換することができます。 例えば、あるタイムゾーンでの時刻が UTC で何時なのかを調べたい場合は、以下のようにします。\n\u0026gt;\u0026gt;\u0026gt; dt_aware.astimezone(pytz.utc) datetime.datetime(2018, 12, 31, 23, 0, tzinfo=\u0026lt;UTC\u0026gt;) ちなみに、引数に何も与えないと、マシンのローカルタイムゾーンに変換されるようです。\n\u0026gt;\u0026gt;\u0026gt; dt_aware.astimezone() datetime.datetime(2019, 1, 1, 8, 0, tzinfo=datetime.timezone(datetime.timedelta(0, 32400), \u0026#39;JST\u0026#39;)) References  datetime \u0026mdash; 基本的な日付型および時間型 — Python documentation Python 製ジオコーディングライブラリ Geocoder を試す - Astropenguin  ","date":"2019-01-19T20:50:59+09:00","permalink":"https://astropengu.in/posts/25/","title":"Python のタイムゾーン関連まとめ"},{"content":"TL;DR 🎄 これはアドベントカレンダーの18日目の記事です。 だいぶ日が開いてしまいましたが、前回の続き として、Hugo で作成したウェブサイトを Travis CI で自動ビルド→プッシュするための設定を行います。\n","date":"2018-12-18T22:44:00+09:00","permalink":"https://astropengu.in/posts/24/","title":"Hugo を使ったウェブサイトの作成: Travis CI の設定"},{"content":"TL;DR 🎄 これはアドベントカレンダーの17日目の記事です。 今日は、Python のパッケージのインストールで使われる setup.py の内容を、設定ファイル setup.cfg に切り出して管理するための方法をまとめました。\nsetup.py \u0026amp; setup.cfg setup.py は、Python のパッケージを pip などでインストールする際に、パッケージの情報やインストール方法などを記述した Python スクリプトです。 2018年現在は、このスクリプトの中で setuptools をインポートし、以下のように記述するのが一般的です。\nfrom setuptools import setup setup(name=\u0026#39;sample\u0026#39;, version=\u0026#39;0.1\u0026#39;, author=\u0026#39;astropenguin\u0026#39;, ...) setup 関数の引数は少ない場合でも10個近くあるため、これをコードから分離して、設定ファイルとして管理できると良さそうです。 そのような理由で setuptools v30.3.0 (2016年12月) から、setup.py と同階層に設定ファイル setup.cfg を置くと、setup 関数の実行時にこれを読み込むようになったそうです。 この場合の setup.py は以下を書くだけで OK です。\nfrom setuptools import setup setup() # without any parameters! Example of setup.cfg 実際の setup.cfg の書き方は、Configuring setup() using setup.cfg files にまとまっています。 以下はこのページに載っていた書き方の引用です。\n[metadata] name = my_package version = attr: src.VERSION description = My package description long_description = file: README.rst, CHANGELOG.rst, LICENSE.rst keywords = one, two license = BSD 3-Clause License classifiers =Framework :: Django Programming Language :: Python :: 3 Programming Language :: Python :: 3.5 [options] zip_safe = False include_package_data = True packages = find: scripts =bin/first.py bin/second.py install_requires =requests importlib; python_version == \u0026#34;2.6\u0026#34; [options.package_data] * = *.txt, *.rst hello = *.msg [options.extras_require] pdf = ReportLab\u0026gt;=1.2; RXP rest = docutils\u0026gt;=0.3; pack ==1.1, ==1.3 [options.packages.find] exclude =src.subpackage1 src.subpackage2 [options.data_files] /etc/my_package =site.d/00_default.conf host.d/00_default.conf data = data/img/logo.png, data/svg/icon.svg セクション ([name]) の書き方から、INIファイルと同様のフォーマットとなっているようです。 これから、[metadata] と [options] の2つのセクションから構成されることが分かります。 また、[options] セクションには、[options.name] のように (サブ) セクションを持っています。\nただし、コメント開始文字がセミコロン (;) ではなくナンバーサイン (#) であり、文字列のセミコロン区切りは意味を持っていることに注意が必要です。 これらの記法は以下にまとまっています。\n metadata の記法 \u0026ndash; setuptools documentation options の記法 \u0026ndash; setuptools documentation  setuptools-py2cfg もしすでにパッケージの setup.py を書いているのであれば、setuptools-py2cfg というツールによって内容を setup.cfg に変換できます。 色々と覚えるよりも、まずはこれで変換してみる方が楽な気がしました。\n$ pip install setuptools-py2cfg $ setuptools-py2cfg /path/to/setup.py pyproject.toml この記事を書くために setuptools 関連を調べていたところ、これらは pyproject.toml という PEP 518 で標準化された設定ファイルで置き換えられる可能性があるそうです。\n Pip builds packages by invoking the build system. Presently, the only supported build system is setuptools, but in the future, pip will support PEP 517 which allows projects to specify an alternative build system in a pyproject.toml file. - pip documentation\n パッケージングや環境構築関連は、この先まだまだ変化がありそうです。 それにしても、TOML が本格的に Python に入ってくる可能性もあるのですね\u0026hellip;\nReferences  Welcome to Setuptools’ documentation! — setuptools documentation Configuring setup() using setup.cfg files — setuptools documentation setuptools-py2cfg PEP 518 -- Specifying Minimum Build System Requirements for Python Projects | Python.org Poetry: Python の依存関係管理とパッケージングを支援するツール | org-技術 Pythonとパッケージングと私  ","date":"2018-12-17T20:43:36+09:00","permalink":"https://astropengu.in/posts/23/","title":"Python の setup.py の内容を setup.cfg で管理する"},{"content":"TL;DR 🎄 これはアドベントカレンダーの16日目の記事です。 今日は雑ですが、Hugo に標準で実装されている、ショートコードを使ったメディアの埋め込みのメモです。\nEmbedding an Instagram photo Hugo は {{/* params */}} のフォーマットで、各種ショートコードを提供しています。 例えば、下の写真は以下のショートコードで埋め込んでいます。\n{{\u0026lt; instagram BrfsVjEhud0 hidecaption \u0026gt;}} \u0026lt;script\u0026gt; タグを使って埋め込むよりも簡単かつ読みやすい Markdown になるので便利ですね。 ちなみに、ショートコードをコードとして表示する際は、 {{\u0026lt;/* params */\u0026gt;}} と書かないと \u0026lt;pre\u0026gt; タグの中でも Hugo によって変換されてしまうため注意が必要です。\nReferences  Shortcodes | Hugo  ","date":"2018-12-16T01:33:19+09:00","permalink":"https://astropengu.in/posts/22/","title":"Hugo shortcode を使った Instagram 埋め込みテスト"},{"content":"TL;DR 🎄 これはアドベントカレンダーの15日目の記事です。 今日は、Python の関数出力を一時的に変化させないようにキャッシュするという、わりとマニアックな話のメモです。\nTemporary caching of function\u0026rsquo;s return 例えば、ユーザからクエリを受け取り、何かファイルからデータを読み込み、該当する値を返す処理を考えます。\ndef get_value(query): data = load(filename) return data[query] このように書くことで、ファイルに変更があった場合もその都度関数がロードするため、常に最新の値を得ることができます。 一方、以下のように大量のクエリを処理する場合、クエリの数だけロードが発生するので、もしファイルが巨大な場合I/Oで非常に時間がかかることが予想されます。\nfor query in million_query_list: value = get_value(query) ... # 値に対する何かの処理 そこで、get_value 関数自体は変更することなく、for 文の中だけ load 関数の出力を凍結 (キャッシュ) することができないか考えてみます。 これは、load 関数をキャッシュ化した関数を作成し、一時的に load 関数と置き換えてあげることで可能になります。 また、\u0026quot;for 文の中\u0026quot; などのコンテクストを扱いたいので、with 文を使ったコンテキストマネージャを使ってあげれば良いことも分かります。\nFreeze context manager というわけで、以下のようなコンテクストマネージャを作成しました。 with freeze(func, module) のように関数とこれが属するモジュールを与えることにより、with 文の中では func() が最初に返した値を常に返すようになります。\nfrom inspect import getmodule class freeze: def __init__(self, func, module=None): self.func = func self.module = module or getmodule(func) def frozen(self, *args, **kwargs): if hasattr(self, \u0026#39;cache\u0026#39;): return self.cache self.cache = self.func(*args, **kwargs) return self.cache def __enter__(self): setattr(self.module, self.func.__name__, self.frozen) def __exit__(self, exc_type, exc_value, traceback): setattr(self.module, self.func.__name__, self.func) An example これをテストするため、以下のような現在時刻を返す now 関数を作成しました。\nfrom datetime import datetime def now(): return datetime.now() これを普通に3連続で実行すると、マイクロ秒単位で異なる時間を返すはずです。\nprint(now()) print(now()) print(now()) # 2018-12-15 23:08:20.573039 # 2018-12-15 23:08:20.573235 # 2018-12-15 23:08:20.573312 今度はこれを、freeze コンテクストマネージャの下で実行してみます。\nwith freeze(now): print(now()) print(now()) print(now()) print(now()) # 2018-12-17 23:08:29.831403 # 2018-12-17 23:08:29.831403 # 2018-12-17 23:08:29.831403 # 2018-12-17 23:08:29.831526 このように、with 文中では、最初に呼び出された時刻を返し続けることが分かります。 また、with 文の外では、再び現在時刻を返していることが確認できました。\n","date":"2018-12-15T01:32:30+09:00","permalink":"https://astropengu.in/posts/21/","title":"Python で一時的に関数出力を凍結 (キャッシュ) する"},{"content":"TL;DR 🎄 これはアドベントカレンダーの14日目の記事です。 2018年の Python プロジェクトのはじめかた にもあるように、pipenv の登場によって Python でも依存関係 (Python バージョン + パッケージ) を両方管理した環境構築が簡単にできるようになりました。 そうなると、IPython や Jupyter の設定ファイルや、パッケージのインポートなどを記述できる IPython のスタートアップスクリプトも環境ごとに管理したいところです。 そこで、この記事では pipenv で作成した環境でこれらを管理する方法をまとめます。\nCreate an environment 前提条件として、以下のコマンドで pipenv で作成した仮想環境 (ここでは名前を env とします) と、IPython/Jupyter がインストール済みであるとします。 特に明記がない限り、コマンドは env から実行しているものとします。 また、仮想環境に (pipenv shell で) 入ってコマンドを実行している場合は、プロンプトを (env) $  として表しました。\n$ mkdir env \u0026amp;\u0026amp; cd env $ pipenv --python 3 $ pipenv install ipython jupyter IPython profile IPython 関連は、プロファイルと呼ばれるディレクトリとファイル群によって設定されます。 通常これは ipython profile create default によって、~/.ipython/profile_default に作成されることが多いと思いますが、何もしないと仮想環境でもこれを引き継いで使ってしまうため、あまり使い勝手がよくありません。 そこで、env 以下にプロファイルを作成し、これを読み込むように pipenv を設定します。\nまず、.env ファイルに以下の環境変数を書き込むことで、pipenv 実行時には env/.ipython が ~/.ipython の代わりに IPython ディレクトリとして使われるようになります。\n$ echo IPYTHONDIR=`pwd`/.ipython \u0026gt;\u0026gt; .env この状態で以下のようにプロファイルを作成することで、env/.ipython/profile_default が作成されます。\n$ pipenv shell (env) $ mkdir -p .ipython (env) $ ipython profile create default 例えば、スタートアップスクリプトで何かパッケージをインポートするようにしてみましょう。\n# import this で Zen of Python を表示 (env) $ echo \u0026#39;import this\u0026#39; \u0026gt;\u0026gt; .ipython/profile_default/startup/01.py この状態で IPython shell を起動してみます。 以下のように、Zen of Python が表示されれば成功です。\n(env) $ ipython Loading .env environment variables… Python 3.6.5 (default, Jul 10 2018, 11:33:24) Type \u0026#39;copyright\u0026#39;, \u0026#39;credits\u0026#39; or \u0026#39;license\u0026#39; for more information IPython 7.2.0 -- An enhanced Interactive Python. Type \u0026#39;?\u0026#39; for help. The Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. ... Create a Jupyter kernel 上で作成したプロファイルを Jupyter Notebook でも使用したい場合、プロファイルを受け取れるような IPython kernel を作成してあげる必要があります。 以下のコマンドで、.venv 以下にカーネルが作成されます。\n(env) $ ipython kernel install --sys-prefix --profile default --display-name Default Installed kernelspec python3 in /path/to/env/.venv/share/jupyter/kernels/python3 オプションのうち、--profile は IPython プロファイル名と同じにしておきます。 --display-name はブラウザで表示される任意のカーネル名です。 この状態で Jupyter Notebook を起動してみます。\n(env) $ jupyter notebook ウェブブラウザが開き、新規ノートブック作成 (New) から上で設定したカーネル (ここでは Default) が選べるようになっていれば成功です。\n \nDemo repository ここまでの手順は、スクリプトにまとめて pipenv のスクリプトショートカット から実行できるようにしておくと便利です。 そこで、これのデモ用に以下のレポジトリを GitHub で公開しました。\n🐧 astropenguin/pipenv-ipython-jupyter: Demo of IPython/Jupyter custom config management by Python-pipenv\nこのレポジトリには、etc/configure に一連のスクリプトが記述されています。 レポジトリを clone したのち、以下の通りに実行すると、上記の諸々の設定が自動で行われます。\n$ pipenv install $ pipenv run configure あとは、.ipython/profile_default を git で管理するなりすれば、環境構築がさらに楽になるはずです！\nReferences  Overview of the IPython configuration system — IPython documentation Installing the IPython kernel \u0026ndash; IPython documentation Custom Script Shortcuts — pipenv documentation Automatic Loading of .env \u0026ndash; pipenv documentation 2018年の Python プロジェクトのはじめかた - Qiita astropenguin/pipenv-ipython-jupyter: Demo of IPython/Jupyter custom config management by Python-pipenv  ","date":"2018-12-14T12:28:08+09:00","permalink":"https://astropengu.in/posts/20/","title":"IPython/Jupyter の設定も pipenv で管理する"},{"content":"TL;DR 🎄 これはアドベントカレンダーの13日目の記事です。 最近私の周りで non-LTE 放射輸送計算コード RADEX を使う人が増えてきたので、ビルドとインストールを GNU make や Homebrew で行えるようにしたという話です。\nCreate Makefile RADEX を使うためには、通常は ウェブサイトからソースコードをダウンロードし、説明に従ってビルドします。 その際、光子の脱出確率を決めるために ISM の geometry を与えたり、分子の Einstein 係数や衝突係数のデータファイルを格納するためのディレクトリを指定したりする必要があり、自動インストーラを作成するのには向いていないツールです。 そこで、これらを以下の通りに解決することで、インストーラを作成していくことにします。\n ISM geometry ごとに異なる RADEX バイナリをビルドすることにする。これによって、3つのバイナリ radex-uni (uniform sphere) 、radex-lvg (expanding sphere) 、radex-slab (plane parallel slab) が生成される。 データディレクトリはデフォルトでは与えない。その代わり、RADEX 実行時にユーザがデータファイルのフルパスを指定する。  GNU make インストーラとしては、GNU make を選びました。 これは、だいたいどの環境でもデフォルトで make コマンドが用意されているためです。 というわけで、出来上がったものを以下で公開しました。\n⚡ astropenguin/radex-install: Build and Install RADEX easily\n使い方は README に書いてある通りですが、ビルドに必要な gfortran をインストールした上で Makefile をダウンロードし、同ディレクトリで\n$ make install するだけで RADEX バイナリのインストールが完了します。 これまでの手間を考えると、とても良い感じです。\nHomebrew さらに、この Makefile を使って Homebrew formula も作成しました。\n🍺 astropenguin/homebrew-formulae: Homebrew formulae for various tools\nこちらは、以下の2行で gfortran のインストールも同時にやってくれます。\n$ brew tap astropenguin/formulae $ brew install radex かなり便利になりました！\nReferences  Radex: Non-LTE molecular radiative transfer in homogeneous interstellar clouds astropenguin/radex-install: Build and Install RADEX easily astropenguin/homebrew-formulae: Homebrew formulae for various tools  ","date":"2018-12-13T02:13:09+09:00","permalink":"https://astropengu.in/posts/19/","title":"RADEX の自動インストーラを作成する"},{"content":"TL;DR 🎄 これはアドベントカレンダーの12日目の記事です。 今日は、Python 製のジオコーディングライブラリの Geocoder を試してみたという話です。\nWhy geocoding? 地上望遠鏡の観測の際には、その地点での天体の方位角と仰角 (az, el) が一日の中でどう変化するかを知ることが重要です。 このような理由から、(az, el) プロット作成するためのコマンドラインツール Azely を開発しているのですが、計算には天体の赤道座標値の他に、望遠鏡の緯度経度 (lat, lng) の座標値が必要になります。 天体座標は、例えば Astropy を使うことで天体名から検索することができます。 そこで、望遠鏡座標も地名 (e.g., 野辺山宇宙電波観測所) から検索 (ジオコーディング) できると便利です。\nGeocoder  Simple and consistent geocoding library written in Python.\n Geocoder   Geocoder は、複数のマップサービスのジオコーディング API を統一された文法 (メソッド) で扱うことができる Python 製ライブラリです。 一般的に API が返す JSON の結果はサービスごとに独自のため、これをプログラムの中で使うために独自のコードを書く必要があるのですが、Geocoder を使うと API の中身を気にせず簡単にジオコーディングを行うことができます。 ちなみに、README によるとおよそ30個のマップサービスに対応しているそうです…すごい。 この中には、API キーの必要ない OpenStreetMap なども含まれているので、Azely の中ではこうしたサービスを使うのが良さそうです。\nInstallation Python パッケージなので、pip でインストール可能です。\n$ pip install geocoder 同時にコマンドラインツールも使えるようになるそうですが、ここでは扱いません。\nUsage Geocoding (OpenStreetMap) 例えば OpenStreetMap で野辺山宇宙電波観測所の座標を取得する場合、たったこれだけで取得できます。\n\u0026gt;\u0026gt;\u0026gt; import geocoder \u0026gt;\u0026gt;\u0026gt; ret = geocoder.osm(\u0026#39;野辺山宇宙電波観測所\u0026#39;, timeout=5.0) \u0026gt;\u0026gt;\u0026gt; print(ret.latlng) [35.9429899, 138.473690612737] ここで、ret はジオコーディングオブジェクトで、以下のようなメソッド (プロパティ) を持っています (他にもあります)。 ret.ok は、ネット接続がなかったり、タイムアウトの場合に False を返します。 参考までに、ret.json を Appendix に置いておきます。\n   Method Description     lat 緯度 (deg) の float   lng 経度 (deg) の float   latlng [緯度, 経度] のリスト   address 住所の文字列   location 場所の名前   json 取得された JSON の dict   geojson GeoJSON 形式の dict   ok 取得が成功したかを示す boolean    また、他にも以下は上手く取得できました。 ただし、'ASTE' や 'ALMA' だけだと別の場所が選ばれてしまうので、ある程度のヒントは必要なようです。\n\u0026gt;\u0026gt;\u0026gt; ret = geocoder.osm(\u0026#39;ASTE telescope\u0026#39;) \u0026gt;\u0026gt;\u0026gt; print(ret.address) ASTE (Atacama Submillimeter Telescope Experiment), San Pedro de Atacama, Provincia de El Loa, Región de Antofagasta, Chile \u0026gt;\u0026gt;\u0026gt; ret = geocoder.osm(\u0026#39;NANTEN2\u0026#39;) \u0026gt;\u0026gt;\u0026gt; print(ret.address) NANTEN2, San Pedro de Atacama - Paso Jama, San Pedro de Atacama, Provincia de El Loa, Región de Antofagasta, Chile \u0026gt;\u0026gt;\u0026gt; ret = geocoder.osm(\u0026#39;ALMA AOS\u0026#39;) \u0026gt;\u0026gt;\u0026gt; print(ret.address) AOS, San Pedro de Atacama, Provincia de El Loa, Región de Antofagasta, Chile Geocoding (IP address) 地味に便利そうなのが、ユーザの IP アドレスから場所を取得できる機能です。 ここで取得できるのはざっくりとした値にすぎませんが、例えば以下を名古屋市から実行した場合、住所が正しく取得できていることが分かります。\n\u0026gt;\u0026gt;\u0026gt; ret = geocoder.ip(\u0026#39;me\u0026#39;) \u0026gt;\u0026gt;\u0026gt; print(ret.address) Nagoya, Aichi, JP References  Geocoder: Simple, Consistent — geocoder 1.38.1 documentation DenisCarriere/geocoder: Python Geocoder OpenStreetMap Japan | 自由な地図をみんなの手に/The Free Wiki World Map astropenguin/azely: Calculate azimuth/elevation of astronomical objects  Appendix {\u0026#39;accuracy\u0026#39;: 0.31000000000000005, \u0026#39;address\u0026#39;: \u0026#39;野辺山宇宙電波観測所, 南牧村, 南佐久郡, 長野県, 中部地方, 日本\u0026#39;, \u0026#39;bbox\u0026#39;: [138.4686251, 35.9401096, 138.4767526, 35.9453509], \u0026#39;confidence\u0026#39;: 8, \u0026#39;country\u0026#39;: \u0026#39;日本\u0026#39;, \u0026#39;country_code\u0026#39;: \u0026#39;jp\u0026#39;, \u0026#39;county\u0026#39;: \u0026#39;南佐久郡\u0026#39;, \u0026#39;importance\u0026#39;: 0.31000000000000005, \u0026#39;lat\u0026#39;: 35.9429899, \u0026#39;lng\u0026#39;: 138.473690612737, \u0026#39;ok\u0026#39;: True, \u0026#39;osm_id\u0026#39;: \u0026#39;133160162\u0026#39;, \u0026#39;osm_type\u0026#39;: \u0026#39;way\u0026#39;, \u0026#39;place_id\u0026#39;: \u0026#39;105994825\u0026#39;, \u0026#39;place_rank\u0026#39;: \u0026#39;22\u0026#39;, \u0026#39;quality\u0026#39;: \u0026#39;observatory\u0026#39;, \u0026#39;raw\u0026#39;: {\u0026#39;place_id\u0026#39;: \u0026#39;105994825\u0026#39;, \u0026#39;licence\u0026#39;: \u0026#39;Data © OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright\u0026#39;, \u0026#39;osm_type\u0026#39;: \u0026#39;way\u0026#39;, \u0026#39;osm_id\u0026#39;: \u0026#39;133160162\u0026#39;, \u0026#39;boundingbox\u0026#39;: [\u0026#39;35.9401096\u0026#39;, \u0026#39;35.9453509\u0026#39;, \u0026#39;138.4686251\u0026#39;, \u0026#39;138.4767526\u0026#39;], \u0026#39;lat\u0026#39;: \u0026#39;35.9429899\u0026#39;, \u0026#39;lon\u0026#39;: \u0026#39;138.473690612737\u0026#39;, \u0026#39;display_name\u0026#39;: \u0026#39;野辺山宇宙電波観測所, 南牧村, 南佐久郡, 長野県, 中部地方, 日本\u0026#39;, \u0026#39;place_rank\u0026#39;: \u0026#39;22\u0026#39;, \u0026#39;category\u0026#39;: \u0026#39;landuse\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;observatory\u0026#39;, \u0026#39;importance\u0026#39;: 0.31000000000000005, \u0026#39;address\u0026#39;: {\u0026#39;address100\u0026#39;: \u0026#39;野辺山宇宙電波観測所\u0026#39;, \u0026#39;village\u0026#39;: \u0026#39;南牧村\u0026#39;, \u0026#39;county\u0026#39;: \u0026#39;南佐久郡\u0026#39;, \u0026#39;state\u0026#39;: \u0026#39;中部地方\u0026#39;, \u0026#39;country\u0026#39;: \u0026#39;日本\u0026#39;, \u0026#39;country_code\u0026#39;: \u0026#39;jp\u0026#39;}}, \u0026#39;region\u0026#39;: \u0026#39;中部地方\u0026#39;, \u0026#39;state\u0026#39;: \u0026#39;中部地方\u0026#39;, \u0026#39;status\u0026#39;: \u0026#39;OK\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;observatory\u0026#39;, \u0026#39;village\u0026#39;: \u0026#39;南牧村\u0026#39;} ","date":"2018-12-12T01:51:14+09:00","permalink":"https://astropengu.in/posts/18/","title":"Python 製ジオコーディングライブラリ Geocoder を試す"},{"content":"TL;DR 🎄 これはアドベントカレンダーの11日目の記事です。 今日は雑ですが、プログラミング用フォント Ricty のインストールのメモです。\nRicty  Ricty (リクティ) は Linux 環境での研究・開発を想定したプログラミング用フォントです。 テキストエディタやターミナルエミュレータ、プログラミング言語やマークアップ言語に対する使用に適しています。\n  プログラミング用フォント Ricty  ということで、これを VS Code や Terminal のフォントとして設定すると見やすくなりそうです。\nInstallation インストールは Homebrew で行えます。 インストール後に以下の通りの caveats が出ますので、その通りにします。\n==\u0026gt; Caveats *************************************************** Generated files: /usr/local/opt/ricty/share/fonts/RictyDiscord-Regular.ttf /usr/local/opt/ricty/share/fonts/Ricty-Bold.ttf /usr/local/opt/ricty/share/fonts/Ricty-Regular.ttf /usr/local/opt/ricty/share/fonts/RictyDiscord-Bold.ttf *************************************************** To install Ricty: $ cp -f /usr/local/opt/ricty/share/fonts/Ricty*.ttf ~/Library/Fonts/ $ fc-cache -vf *************************************************** というわけで、全てのスクリプトは以下の通りです。\n$ brew tap sanemat/font $ brew install ricty $ cp -f /usr/local/opt/ricty/share/fonts/Ricty*.ttf ~/Library/Fonts/ $ fc-cache -vf VS Code に設定したらこんな感じになりました！\n \nReferences  プログラミング用フォント Ricty プログラミング用フォントRictyをMacにインストールする - Qiita  ","date":"2018-12-11T23:06:55+09:00","permalink":"https://astropengu.in/posts/17/","title":"プログラミング用フォント Ricty のインストール"},{"content":"TL;DR 🎄 これはアドベントカレンダーの10日目の記事です。 今日は昨日の続きで、Hugo で作成したテストサイトの設定をいじっていきます。\nSite configuration (config.toml) Hugo のウェブサイトの設定は config.toml というファイルで行います。 ちなみに TOML (Tom\u0026rsquo;s Obvious, Minimal Language) は JSON や YAML と同様の設定ファイル記述言語です。 今回は最低限の設定として、以下のような設定を書きました。 その他の設定可能な項目は、Configure Hugo にまとまっています。\n# このウェブサイトのタイトル title = \u0026#34;Astropenguin\u0026#34; # サイトの URL のルート baseURL = \u0026#34;https://astropengu.in/\u0026#34; # ウェブサイトのテーマ theme = \u0026#34;minimo\u0026#34; # 日本語の文字カウント等を有効化 hasCJKLanguage = true # 絵文字の有効化 enableEmoji = true # タグでのアクセント記号や大文字小文字の保持 preserveTaxonomyNames = false # シンタックスハイライト有効化とスタイル pygmentsCodefences = true pygmentsStyle = \u0026#34;manni\u0026#34; # タグのアドレス [taxonomies] tag = \u0026#34;tags\u0026#34; # 記事の URL 設定 [permalinks] page = \u0026#34;/:slug/\u0026#34; blog = \u0026#34;/:section/:filename/\u0026#34; # 外部リンクを新規タブで開く [blackfriday] hrefTargetBlank = true この他に、テーマ固有の設定も書く必要がありますが、こちらはテーマによって異なるのでここではまとめません。 Minimo の場合は、作者のデモページ を見てカスタマイズするのが良いと思います。 また、私のフルの config.toml をこちらで確認することもできます。\nReferences  Minimo Configure Hugo | Hugo toml-lang/toml: Tom\u0026rsquo;s Obvious, Minimal Language astropenguin/website: Personal website powered by Hugo  ","date":"2018-12-10T22:50:44+09:00","permalink":"https://astropengu.in/posts/16/","title":"Hugo を使ったウェブサイトの作成: ウェブサイトの設定"},{"content":"TL;DR 🎄 これはアドベントカレンダーの9日目の記事です。 今日は昨日の続きで、いよいよ Hugo を使ってウェブサイトを作成していきます。\nInstall hugo まずは Hugo をローカルにインストールします。 ここでは Homebrew を使ってインストールしました。 また、ついでに Hugo のバージョンも確認しておきましょう。 このバージョンは、後ほど Travis CI でビルドする際の Hugo のバージョンで使うのでメモしておきます\n$ brew install hugo $ hugo version Hugo Static Site Generator v0.52/extended darwin/amd64 BuildDate: unknown ここでは v0.52 であることが確認できました。\nCreate an empty website 次に、Hugo で空のウェブサイトを作成し、Git での管理を開始します。 ここでは website というディレクトリを作成しました。 また、GitHub で website という名前でリモートレポジトリを作成し、これを追加します。\n$ hugo new site website \u0026amp;\u0026amp; cd website $ git init $ git remote add origin https://github.com/astropenguin/website.git この状態のディレクトリ構成は以下のようになっていると思います。\n$ tree -a -L 1 . ├── .git ├── archetypes ├── config.toml ├── content ├── data ├── layouts ├── static └── themes 以下では、特に断りがなければ website ディレクトリで各種コマンドを実行しています。\n$ pwd /path/to/website トップの6個のディレクトリは空でも Git に管理されるように .gitkeep という空のファイルを追加しておきます。 ファイル名は .gitkeep である必要はありませんが、慣習的にこうなっているようです。 また、ビルド結果が保存される public, resources ディレクトリ以下は Git の管理から外すため .gitignore に追記しておきます。\n$ touch archetypes/.gitkeep $ touch content/.gitkeep $ touch data/.gitkeep $ touch layouts/.gitkeep $ touch static/.gitkeep $ touch themes/.gitkeep $ echo /public \u0026gt;\u0026gt; .gitignore $ echo /resources \u0026gt;\u0026gt; .gitignore Choosing a theme ここで、ウェブサイトのテーマを選びます。 テーマは Hugo でウェブサイトをビルドする際に必ず必要となるものです。 今回は、ミニマルなデザインかつ数式表示やウィジェットをサポートしているということで、 Minimo を選びました。 このページからダウンロードしたものを themes ディレクトリに配置しても良いのですが、作者が GitHub で管理しているので、このレポジトリを submodule として追加することにします。\n$ git submodule add https://github.com/MunifTanjim/minimo themes/minimo こうすることで Minimo のコミット ID のみを管理するので、テーマの無数のファイルを website レポジトリで管理しなくてよくなります。 ここまでの作業をコミット→プッシュしておきます。\n$ git add --all $ git commit -m \u0026#34;Initial commit\u0026#34; $ git push origin master An example site Minimo テーマには exampleSite と呼ばれる、文字通りウェブサイトの作成例を示したファイルとディレクトリ (config.toml, content, data, static) が同梱されています。 これをコピーして、ローカルでウェブサイトがどう見えるかチェックしてみます。\n$ cp -r themes/minimo/exampleSite/ . この状態で hugo server を実行することで、 localhost:1313 でウェブサイトをプレビューすることができます。\n$ open http://localhost:1313 \u0026amp;\u0026amp; hugo server こんな感じで表示されれば成功です！\n \n次回からは、ここでコピーしてきた Hugo の設定ファイル (config.toml) を編集することで、私自身のウェブサイトの設定をしていきます。\nReferences  Complete List | Hugo Themes Minimo | Hugo Themes MunifTanjim/minimo: Minimo - Minimalist theme for Hugo  ","date":"2018-12-09T17:40:27+09:00","permalink":"https://astropengu.in/posts/15/","title":"Hugo を使ったウェブサイトの作成: テストサイトの表示"},{"content":"TL;DR 🎄 これはアドベントカレンダーの8日目の記事です。 今日から数回に渡って、このウェブサイト https://astropengu.in の作成方法についてメモしていきます。 まずはウェブサイトの作成に至った経緯と技術選定についてです。\nWhy personal website? このウェブサイトを作ろうと思った経緯について簡単にまとめておきます。 研究を進めていく上で必要な情報のまとめや、何かのツールの使い方の tips を公開する場として、個人ウェブサイトは必要だと思っていました。 学生時代に作成したサイトは大学のサーバに置かせてもらっていましたが (現在もご好意で置かせてもらっていますがそのうち削除すると思います) 、研究者としてしばらくは職場の移動も多いので、研究機関に縛られない環境でウェブサイトを作成する方が色々と楽であると思うようになりました。 ついでに独自ドメインも取得することで、名刺代わりにもなるでしょう。\nSelecting tools というわけでウェブサイトを作成するための技術選定です。 2018年現在、ウェブサイトの公開する手段は無数にあるわけですが、私は以下の点を特に強く意識してツールを選びました。\nプレーンテキストフォーマットで楽に書けること: 記事がプレーンテキストで書けて保存できることで、バージョン管理システムによる管理が容易になります。さらに、特定のフォーマットに従っていることで、将来的にツールを変えた時に移行作業の負担も減ることが予想できます。楽に書けるということを踏まえると、これは軽量マークアップ言語の Markdown ほぼ一択となりそうです。\n特定のウェブサービスに依存しないサイトであること: これは楽に書くということとトレードオフの関係にあるかもしれません。特定のサービスを使うとウェブサイトの管理が楽になる一方、そのサービスが終了してしまった時にサルベージが難しくなります。そこで、Markdown で書かれた記事から動的にページを生成するのではなく、静的な HTML ページを完全に生成することを考えます。こうすることで、生成されたウェブサイトをホストするためのサーバやサービスを転々とできるので、依存度がぐっと下がります。静的なウェブサイト生成 (ビルド) には、静的サイトジェネレータ (static site generator) と呼ばれるツールが使えます。オープンソースで様々なツールが利用可能ですが、ビルドが高速でバイナリファイル一つで動作するという理由で Hugo を選択しました。\nさらに、必須ではありませんが、記事を更新するハードルを下げることも大事なので、ウェブサイトのバージョン管理やビルドについてもなるべく自動化するための仕組みがほしいところです。\nCurrent tools 以上より、2018年12月現在、このウェブサイトは以下のツールやウェブサービスを使って作成・運用しています。 このうち費用がかかっているアイテムには 💰 が付いてます。\n   Item Description     Hugo Golang (Go 言語) で書かれた静的サイトジェネレータ。Markdown で書かれた記事をビルドし、静的な HTML ページを生成するのに使います。   Google Domains 💰 ウェブサイトの独自ドメイン (astropengu.in) の取得・管理に使います。ちなみに .in はインドの ccTLD で、年間 1,500 円ほどで取得しています。   Git \u0026amp; GitHub ご存じ分散型バージョン管理システムとレポジトリのホスティングサービス。Hugo の設定ファイルとビルド前の記事データ (Markdown, 画像等) のレポジトリの管理に使います。これらは astropenguin/website ですべて公開されています。   GitHub Pages GitHub が提供するレポジトリに置かれたウェブサイトのホスティングサービス。Hugo でビルドした生成物を公開するのに使います。   Travis CI ビルドやテストを行うためのオンラインの継続的インテグレーション (CI) サービス。記事を作成・更新してプッシュするたびに、レポジトリの取得 → Hugoでビルド → 生成物をレポジトリの gh-pages ブランチにプッシュ、という一連の流れを自動的に行い、ウェブサイトを自動更新するのに使います。    こうしてみると、利用しているツールは多いですね。 ただし、Git(Hub) と CI はウェブサイト以外にも使える汎用性のある技術なので、学ぶ価値が大いにあります。 独自ドメインに関しては、ウェブサイトを公開するというだけなら特に必要ありません。 ということで、ウェブサイトのためだけに新規に学ぶのは Hugo の使い方ということになります。\nOther choices? もし、ウェブサイトを公開するためのサーバを自由に使えるのだとしたら、フラットファイル CMS と呼ばれるツールも選択肢の一つかもしれません。 これは、記事を Markdown ファイルで管理しつつ、サーバ上でページを動的に生成するタイプのツールなので、記事の管理とウェブサイトの公開の手間という意味ではバランスが取れている気がします。 2018年現在でおそらく最も情報があって使いやすいのは Grav だと思います (私も少しの間使ってました)。\nまた、研究プロジェクト単位で複数人かつクローズな情報共有という意味では、Kibela や esa をはじめとするオンライン Markdown 情報共有ツールが有用です。 これについては、どこかの機会に別記事でまとめておきたいところです。\nReferences  astropenguin/website: Personal website powered by Hugo The world’s fastest framework for building websites | Hugo StaticGen | Top Open Source Static Site Generators Grav - A Modern Flat-File CMS | Grav Kibela - 個人の発信を組織の力にする情報共有ツール esa - 自律的なチームのための情報共有サービス  ","date":"2018-12-08T22:52:48+09:00","permalink":"https://astropengu.in/posts/14/","title":"Hugo を使ったウェブサイトの作成: 技術選定"},{"content":"TL;DR 🎄 これはアドベントカレンダーの7日目の記事です。 今日は雑ですが、Slack のサイドバーのカスタムテーマ集のサイトの紹介と設定方法のメモです。\nSlack Themes Slack Themes というサイトが便利そうです。 様々なカスタムテーマが紹介されており、その場で実際の Slack でどう表示されるかプレビューが見られます。 アドベントカレンダーということで、ここではクリスマスっぽいテーマを選択してみました。\n \nあとは、表示されているカラーコードをコピーして、 Slack の 環境設定 → サイドバー → カスタムテーマ に貼り付ければ設定完了です。\n \n","date":"2018-12-07T09:51:31+09:00","permalink":"https://astropengu.in/posts/13/","title":"Slack のカスタムテーマの設定"},{"content":"TL;DR 🎄 これはアドベントカレンダーの6日目の記事です。 今日は昨日の続きで、Linuxbrew を利用して ADC/MDAS に tmux をインストールした話です。\nInstall tmux by Linuxbrew ALMAデータのキャリブレーションやイメージングなどの重い処理の際に、ネットワークトラブルなどで不意にSSH接続が切れてしまい最初から作業のやり直し、というのは大変です。 また、複数のデータを並行して処理したい時に処理の数だけターミナルをを開くのも面倒です。 そこで、SSH接続が切れてもサーバ上の処理を継続させたり、1つのSSH接続で複数の処理を並行して実行できたりできる、tmux (terminal multiplexer) というソフトウェアを使うのがとても便利です。 昨日の記事で Linuxbrew が準備できているので、インストールはとても簡単です。\n$ brew install tmux ただし、Linuxbrew で git と curl をインストールしている影響で、そのまま tmux を起動すると以下のようなメッセージが出ます (tmux 自体は動きます) 。\n$ tmux Package bash-completion was not found in the pkg-config search path. Perhaps you should add the directory containing `bash-completion.pc\u0026#39; to the PKG_CONFIG_PATH environment variable No package \u0026#39;bash-completion\u0026#39; found bash: /yum: No such file or directory これを回避するためには、以下を .bash_profile に書いておけば OK です。\n$ echo \u0026#39;export PKG_CONFIG_PATH=$PKG_CONFIG_PATH:/usr/share/pkgconfig\u0026#39; \u0026gt;\u0026gt; ~/.bash_profile References  tmux/tmux: tmux source code Linuxbrew: \u0026ldquo;Package bash-completion was not found...\u0026rdquo; at command prompt. · Issue #46 · Linuxbrew/legacy-linuxbrew  ","date":"2018-12-06T12:16:40+09:00","permalink":"https://astropengu.in/posts/12/","title":"ADC/MDAS への tmux のインストール"},{"content":"TL;DR 🎄 これはアドベントカレンダーの5日目の記事です。 今日は天文データセンター (ADC) の多波長データ解析システム (MDAS) に Linuxbrew をインストールする際の手順をまとめました。\nLinuxbrew on ADC/MDAS Linuxbrew は macOS で使われているパッケージ管理システム Homebrew の Linux 版です。 ADC/MDAS では一般ユーザは root 権限を持たないので、何かパッケージをインストールするときに root 権限を必要としない Linuxbrew を使えるととても便利です。\nInstallation インストールは Install Linuxbrew に従っておけば OK です。 ADC/MDAS にログインした状態で以下を実行します。 これで Linuxbrew の諸々が ~/.linuxbrew に置かれます。\n$ sh -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Linuxbrew/install/master/install.sh)\u0026#34; メモとしてですが、 git と curl を (すでにあるのに) インストールするようで、これらの依存関係をかなりの時間をかけて解決していました。 どうやら、システムの git と curl が最新版よりかなり古い場合、これらも brew でインストールすることになっているようです。 無事インストールが終わったら、Install Linuxbrew にあるように、テストとパスの設定を行います。 ADC/MDAS は OS が RedHat なので、以下の通りで OK です。\n$ test -d ~/.linuxbrew \u0026amp;\u0026amp; eval $(~/.linuxbrew/bin/brew shellenv) $ test -r ~/.bash_profile \u0026amp;\u0026amp; echo \u0026#34;eval \\$($(brew --prefix)/bin/brew shellenv)\u0026#34; \u0026gt;\u0026gt; ~/.bash_profile これでインストール作業完了です！ いったんログアウト→ログインして、コマンド brew doctor が動くか確認してください。\n$ brew doctor Warning は多数出ますが、error が出てなければ問題ないでしょう。 実際にパッケージをインストールする様子は明日以降にまとめたいと思います。\nReferences  Linuxbrew | The Homebrew package manager for Linux The missing package manager for macOS — The missing package manager for macOS brew(1) – The missing package manager for macOS — Homebrew Documentation  ","date":"2018-12-05T18:18:49+09:00","permalink":"https://astropengu.in/posts/11/","title":"ADC/MDAS への Linuxbrew のインストール"},{"content":"TL;DR 🎄 これはアドベントカレンダーの4日目の記事です。 今日は Python で複数行のコードの実行時間を計測する際の書き方をまとめました。\nContext stopwatch 複数行のコードの時間計測では、よく以下のようなコードを見かけます。\nimport time start = time.time() ... # some code ... # some code ... # some code end = time.time() print(f\u0026#39;elapsed time = {end-start:.2f} sec\u0026#39;) これでももちろん問題ないのですが、コードの計測のたびに start や stop をコードの前後に書き加えるのは面倒です。 このような複数行の、すなわちある種の文脈 (context) を扱うのには、Python の標準ライブラリの一つ contextlib を使うのが便利です。 この中の contextmanager を使うと、以下のような stopwatch を作成することができます。\nimport time from contextlib import contextmanager @contextmanager def stopwatch(): start = time.time() yield end = time.time() print(f\u0026#39;elapsed time = {end-start:.2f} sec\u0026#39;) つまり、with 文の中に入っているコードの実行前に yield の前に書かれた内容が、コードの実行後に yield の後に書かれた内容が自動的に実行されることになります。 これを使うと、上のコードは以下のように書くことができます。\nwith stopwatch(): ... # some code ... # some code ... # some code In IPython or Jupyter notebook IPython や Jupyter notebook 上では、cell magic と呼ばれる書き方によって、以下のようにセル単位で時間計測もできます。 Pure Python では使えませんが、普段使いにはこちらの方が楽かもしれません。\n%%time ... # some code ... # some code ... # some code References  29.6. contextlib — with 文コンテキスト用ユーティリティ — Python 3.6.5 ドキュメント Built-in magic commands — IPython 7.2.0 documentation  ","date":"2018-12-04T21:35:49+09:00","permalink":"https://astropengu.in/posts/10/","title":"Python のコンテキストマネージャを使った複数行の時間計測"},{"content":"TL;DR 🎄 これはアドベントカレンダーの3日目の記事です。 今日は雑ですが、matplotlib のデフォルトスタイルを復元する方法のメモです。\nimport matplotlib.pyplot as plt plt.rcParams.update(plt.rcParamsDefault) ","date":"2018-12-03T21:47:56+09:00","permalink":"https://astropengu.in/posts/9/","title":"Matplotlib のデフォルトスタイルの復元方法"},{"content":"TL;DR 🎄 これはアドベントカレンダーの2日目の記事です。 Pythonにおけるシングルトンの実装を試してみた際のメモです。\nSingleton in Python シングルトンはメタクラスとして実装することができます。 仕組みとしては単純で、もしメタクラスが最初に呼び出された場合は通常のインスタンス生成と同様に type(name, bases, dict) が呼ばれ、そうでない場合は格納されたインスタンスを返すようにすれば良いです。\nclass Singleton(type): _instances = {} def __call__(cls, *args, **kwargs): if cls not in cls._instances: cls._instances[cls] = super().__call__(*args, **kwargs) return cls._instances[cls] 以下のコードでシングルトンのクラスの振る舞いを確かめてみます。 ちなみに、total_ordering デコレータは比較演算子の実装を楽にするためのものです。\nfrom functools import total_ordering @total_ordering class TestClass(metaclass=Singleton): def __init__(self, value): self.value = value def __eq__(self, other): if not isinstance(other, self.__class__): return NotImplemented return self.value == other.value def __lt__(self, other): if not isinstance(other, self.__class__): return NotImplemented return self.value \u0026lt; other.value instance_1 = TestClass(1) instance_2 = TestClass(2) print(instance_1 == instance_2) # 同値性チェック print(instance_1 is instance_2) # 同一性チェック print(instance_1.value) print(instance_2.value) 結果は次のようになります。\nTrue True 1 1 後に生成されたインスタンスは、最初と違う引数で生成されたのにも関わらず、最初に生成されたインスタンスと同一であることが分かります。\nReferences  10.2. functools — 高階関数と呼び出し可能オブジェクトの操作 — Python 3.6.5 ドキュメント  ","date":"2018-12-02T00:58:38+09:00","permalink":"https://astropengu.in/posts/8/","title":"Python におけるシングルトンの実装"},{"content":"TL;DR 🎄 ウェブサイトへのアウトプットを軌道に乗せるため、アドベントカレンダーをやってみることにします。 というわけでこれはアドベントカレンダー1日目の記事です。\nLinux では標準出力をターミナルに表示しつつファイルにも保存したい時、以下のように tee コマンドを使いますが、これと同様の結果を IPython shell 上でも実現したい時の方法をまとめておきます。\n\u0026lt;some command\u0026gt; | tee result.log IPython.utils.io.Tee IPython パッケージの中に、そのものずばりの Tee クラスが用意されています。 以下のように記録したいコードの前後で以下のように記録することで、print 関数等の標準出力が同時にファイルにも保存されます。\nfrom IPython.utils.io import Tee f = Tee(\u0026#39;result.log\u0026#39;) ... # some script f.close() もちろん、パッケージ開発の際は、ユーザがこのような対応を取らなくて良いように、Python のロギング機能を使うのが良いように思います。\nReferences  Module: utils.io — IPython 7.2.0 documentation logging --- Python 用ロギング機能 — Python 3.7.1 ドキュメント  ","date":"2018-12-01T23:54:06+09:00","permalink":"https://astropengu.in/posts/7/","title":"IPython shell で tee を実現する"},{"content":"ALMA Phase 2 submission のために Science Potal を久しぶりに見てみたら、 Tools にこんなものが紹介されていたのでメモ。\n http://radio-astro-tools.gitub.io https://github.com/radio-astro-tools  実は 2017年9月に CASA News で紹介されてました。 まだほとんど見れていないけれど、解析ツールとして使えるかぜひ検討してみたいところです。\n","date":"2018-12-01T22:44:51+09:00","permalink":"https://astropengu.in/posts/6/","title":"Radio Astro Tools"},{"content":"シンボリックリンクのパス指定についてメモ。 ln -s で貼るときのリンク元・リンクのパスは、\n$ ln -s \u0026lt;リンク元の絶対パス\u0026gt; \u0026lt;リンクのパス\u0026gt; または、\n$ ln -s \u0026lt;リンクから見たリンク元の相対パス\u0026gt; \u0026lt;リンクのパス\u0026gt; と指定する。 \u0026lt;リンクのパス\u0026gt; は絶対パスでも、現在のディレクトリから見た相対パスでも良い。 基本的には絶対パスで指定しておくのが良いだろう。 どちらのパスにもスラッシュは付けないようにする。 また、リンクを削除する際は rm ではなく unlink を使うとリンク元をうっかり削除してしまうのを防げるので良いだろう。\nReferences  【ln -s】シンボリックリンクをちゃんと理解―絶対パス 相対パスでのリンク張り - tweeeetyのぶろぐ的めも シンボリックリンクの作成と削除 - Qiita  ","date":"2018-12-01T18:41:48+09:00","permalink":"https://astropengu.in/posts/5/","title":"シンボリックリンクのパス指定"},{"content":"rsync は SSH でのファイル・ディレクトリの転送・バックアップに便利な一方、 オプションが複雑なため間違えるとコピー先のデータを消してしまうこともある。 そこで、転送・バックアップのよく使うオプションについてまとめておく。\nCopy scp 相当の使い方をする場合 $ rsync -av source destination 中断した転送を再開できるようにする場合 $ rsync -avP source destination  -P オプションで destiation に中断時点の一時データが残される  Backup ディレクトリごとバックアップする場合 $ rsync -av --delete source destination  destinationの中にsourceディレクトリがコピーされる 通常はこの使い方をしておけば問題ないと思う  ディレクトリ間でファイルを同期する場合 $ rsync -av --delete source/ destination  sourceの中身がdestinationの中身と同期される destinationの中身が強制的に置き換えられるので注意！  Useful options Referenceより抜粋。\n   Option Description     -a -rlptgoDと指定したのと同様の効果。元のパーミッションやグループなどを保持したまま同期できるので、基本的に付加しておくのがよい。アーカイブモードとも呼ばれる。   -v 処理中の経過ファイル名を表示する。   -P --partial \u0026amp; --progress と同じ。   -z データを圧縮する。   --delete コピー元で削除されたファイルは、コピー先でも削除する。-aオプションと同時に指定することでコピー元とコピー先を同期できることになる。   --dry-run (-n) 実行時の動作だけを表示。テストに使用するとよい。   --partial 転送を中断したファイルを保持する。   --progress 転送の進行状況を表示する。    References  【 rsync 】コマンド（その1）――ファイルやディレクトリを同期する：Linux基本コマンドTips（82） - ＠IT はじめてrsyncを使う方が知っておきたい6つのルール - ITmedia エンタープライズ rsync \u0026ndash;delete で泣かないために - Qiita  ","date":"2018-12-01T18:41:26+09:00","permalink":"https://astropengu.in/posts/4/","title":"rsync を使った転送・バックアップ"},{"content":"画像などの2次元配列で、周囲に非ゼロの値が存在しないような孤立したピクセル値をゼロにしたいことがある。 例えば、天体画像を N-sigma clipping した際に、ノイズの影響で天体以外の場所に残ってしまった スパイク状のゴミを消去したい場合などである。 この場合、あるピクセルの周囲に非ゼロの値がいくつ存在するかを2次元の畳み込みで求めるのが簡単である。\nPython code 2次元のとある NumPy 配列 array があるとする。 このとき、以下のような2次元配列 kernel と畳み込むと、 周囲のピクセル値の和となるような2次元配列を計算できる。\nimport numpy as np kernel = np.array([[1, 1, 1], [1, 0, 1], [1, 1, 1]]) これを応用して、非ゼロを True 、それ以外を False とするような 2次元配列に対して同様の操作をすることで、周囲の非ゼロピクセル数が計算できる。\nfrom scipy.signal import convolve2d # 非ゼロを True で表す condition = (array != 0) # 周囲の非ゼロピクセル数を計算する neighbours = convolve2d(condition, kernel, mode=\u0026#39;same\u0026#39;, boundary=\u0026#39;fill\u0026#39;, fillvalue=0) あとはこれを使って孤立したピクセル (neighbours==0) を処理すれば良い。\n# 周囲に非ゼロの値がないピクセル値をゼロにする array[neighbours==0] = 0 Others 余談だが、この方法を使って Conway\u0026rsquo;s game of life (ライフゲーム) を簡単に実装することができる。\n","date":"2018-12-01T18:40:47+09:00","permalink":"https://astropengu.in/posts/3/","title":"畳み込みによる画像のノイズ除去"},{"content":"Issue VS Code で日本語入力して GitHub にプッシュしたら、以下のように � で表示される文字が紛れ込んでいた。 これは VS Code で使われている Electron のバグで、制御文字 (backspace) が紛れ込んでしまっているようだ。\n \nSolution まず、制御文字が VS Code のエディタ上で表示されるように、 User Settings で以下を設定する。\n{ \u0026#34;editor.renderControlCharacters\u0026#34;: true } さらに、VS Code の拡張機能 Remove backspace control character をインストールすることによって、 万一制御文字が紛れ込んだ場合も保存時に自動的に削除されるようにしておく。 例えば、ファイルの保存時に削除するのであれば、以下のように設定しておけば良い。\n{ \u0026#34;editor.formatOnSave\u0026#34;: true } References  Visual Studio Code の日本語問題まとめ - Qiita Visual Studio Code で制御文字が混ざる問題 - kawaken\u0026rsquo;s blog Remove backspace control character - Visual Studio Marketplace  ","date":"2018-12-01T18:38:39+09:00","permalink":"https://astropengu.in/posts/2/","title":"VS Code の日本語入力で制御文字が紛れ込む問題"},{"content":"以前のウェブサイト (http://www.ioa.s.u-tokyo.ac.jp/~taniguchi/) の移転先として、 こちらの新しいウェブサイト (https://astropengu.in) を Hugo で作成しました。 今後はここに研究や開発の情報をまとめる予定です。 以前のウェブサイトはしばらくの間動いていると思いますが、更新はされませんのでご注意ください。\n","date":"2018-12-01T18:08:51+09:00","permalink":"https://astropengu.in/posts/1/","title":"Hello, world!"}]